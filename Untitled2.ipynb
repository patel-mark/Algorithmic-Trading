{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027679df-8866-4dda-b58a-e311f5fd2027",
   "metadata": {},
   "source": [
    "## Machine Learning Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0085fc6-e5a2-4f0a-a943-08fa754d1e20",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc499a92-d4de-4463-beb7-14b6fe511dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\", rc={\"axes.facecolor\": \"#f0f0f0\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55137ba-4ded-4703-8f0a-a9d0d8f8e81e",
   "metadata": {},
   "source": [
    "### Load Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb70bae-5073-4f73-a984-6e41ac011033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "1    0.558289\n",
      "0    0.441711\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load data from Day 2\n",
    "df = pd.read_csv(\"QQQ_Engineered_Data.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "# Create target variable (1 if next day's close > current day's close)\n",
    "df[\"Target\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
    "df.dropna(subset=[\"Target\"], inplace=True)  # Remove last row with NaN\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop([\"Close\", \"Target\"], axis=1)  # Exclude raw close price to avoid leakage\n",
    "y = df[\"Target\"]\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c960ed-cbe7-428f-b591-b4aee877f11d",
   "metadata": {},
   "source": [
    "### Time-Series Split (Avoid Look-Ahead Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476d91ed-73dd-4fbc-afb5-2d377ce936ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dates: 2010-02-22 00:00:00 to 2022-01-06 00:00:00\n",
      "Test Dates: 2022-01-07 00:00:00 to 2024-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train Dates: {X_train.index.min()} to {X_train.index.max()}\")\n",
    "print(f\"Test Dates: {X_test.index.min()} to {X_test.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140719f1-9a2f-4643-90e4-305222bdc636",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with Time-Series CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e55c905-e9e6-4820-84f4-69b67102f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "[0]\tvalidation_0-logloss:0.68392\n",
      "[1]\tvalidation_0-logloss:0.68293\n",
      "[2]\tvalidation_0-logloss:0.68224\n",
      "[3]\tvalidation_0-logloss:0.68131\n",
      "[4]\tvalidation_0-logloss:0.68046\n",
      "[5]\tvalidation_0-logloss:0.67964\n",
      "[6]\tvalidation_0-logloss:0.67883\n",
      "[7]\tvalidation_0-logloss:0.67806\n",
      "[8]\tvalidation_0-logloss:0.67760\n",
      "[9]\tvalidation_0-logloss:0.67710\n",
      "[10]\tvalidation_0-logloss:0.67643\n",
      "[11]\tvalidation_0-logloss:0.67542\n",
      "[12]\tvalidation_0-logloss:0.67491\n",
      "[13]\tvalidation_0-logloss:0.67430\n",
      "[14]\tvalidation_0-logloss:0.67373\n",
      "[15]\tvalidation_0-logloss:0.67340\n",
      "[16]\tvalidation_0-logloss:0.67242\n",
      "[17]\tvalidation_0-logloss:0.67171\n",
      "[18]\tvalidation_0-logloss:0.67133\n",
      "[19]\tvalidation_0-logloss:0.67093\n",
      "[20]\tvalidation_0-logloss:0.67045\n",
      "[21]\tvalidation_0-logloss:0.66991\n",
      "[22]\tvalidation_0-logloss:0.66938\n",
      "[23]\tvalidation_0-logloss:0.66900\n",
      "[24]\tvalidation_0-logloss:0.66850\n",
      "[25]\tvalidation_0-logloss:0.66821\n",
      "[26]\tvalidation_0-logloss:0.66761\n",
      "[27]\tvalidation_0-logloss:0.66723\n",
      "[28]\tvalidation_0-logloss:0.66686\n",
      "[29]\tvalidation_0-logloss:0.66641\n",
      "[30]\tvalidation_0-logloss:0.66602\n",
      "[31]\tvalidation_0-logloss:0.66540\n",
      "[32]\tvalidation_0-logloss:0.66475\n",
      "[33]\tvalidation_0-logloss:0.66437\n",
      "[34]\tvalidation_0-logloss:0.66381\n",
      "[35]\tvalidation_0-logloss:0.66343\n",
      "[36]\tvalidation_0-logloss:0.66309\n",
      "[37]\tvalidation_0-logloss:0.66247\n",
      "[38]\tvalidation_0-logloss:0.66173\n",
      "[39]\tvalidation_0-logloss:0.66146\n",
      "[40]\tvalidation_0-logloss:0.66074\n",
      "[41]\tvalidation_0-logloss:0.66011\n",
      "[42]\tvalidation_0-logloss:0.65983\n",
      "[43]\tvalidation_0-logloss:0.65945\n",
      "[44]\tvalidation_0-logloss:0.65912\n",
      "[45]\tvalidation_0-logloss:0.65865\n",
      "[46]\tvalidation_0-logloss:0.65817\n",
      "[47]\tvalidation_0-logloss:0.65756\n",
      "[48]\tvalidation_0-logloss:0.65720\n",
      "[49]\tvalidation_0-logloss:0.65669\n",
      "[50]\tvalidation_0-logloss:0.65608\n",
      "[51]\tvalidation_0-logloss:0.65548\n",
      "[52]\tvalidation_0-logloss:0.65494\n",
      "[53]\tvalidation_0-logloss:0.65456\n",
      "[54]\tvalidation_0-logloss:0.65433\n",
      "[55]\tvalidation_0-logloss:0.65377\n",
      "[56]\tvalidation_0-logloss:0.65345\n",
      "[57]\tvalidation_0-logloss:0.65296\n",
      "[58]\tvalidation_0-logloss:0.65267\n",
      "[59]\tvalidation_0-logloss:0.65239\n",
      "[60]\tvalidation_0-logloss:0.65179\n",
      "[61]\tvalidation_0-logloss:0.65137\n",
      "[62]\tvalidation_0-logloss:0.65090\n",
      "[63]\tvalidation_0-logloss:0.65048\n",
      "[64]\tvalidation_0-logloss:0.65022\n",
      "[65]\tvalidation_0-logloss:0.64990\n",
      "[66]\tvalidation_0-logloss:0.64951\n",
      "[67]\tvalidation_0-logloss:0.64907\n",
      "[68]\tvalidation_0-logloss:0.64866\n",
      "[69]\tvalidation_0-logloss:0.64829\n",
      "[70]\tvalidation_0-logloss:0.64764\n",
      "[71]\tvalidation_0-logloss:0.64723\n",
      "[72]\tvalidation_0-logloss:0.64702\n",
      "[73]\tvalidation_0-logloss:0.64652\n",
      "[74]\tvalidation_0-logloss:0.64598\n",
      "[75]\tvalidation_0-logloss:0.64546\n",
      "[76]\tvalidation_0-logloss:0.64492\n",
      "[77]\tvalidation_0-logloss:0.64464\n",
      "[78]\tvalidation_0-logloss:0.64429\n",
      "[79]\tvalidation_0-logloss:0.64396\n",
      "[80]\tvalidation_0-logloss:0.64343\n",
      "[81]\tvalidation_0-logloss:0.64292\n",
      "[82]\tvalidation_0-logloss:0.64228\n",
      "[83]\tvalidation_0-logloss:0.64199\n",
      "[84]\tvalidation_0-logloss:0.64160\n",
      "[85]\tvalidation_0-logloss:0.64124\n",
      "[86]\tvalidation_0-logloss:0.64103\n",
      "[87]\tvalidation_0-logloss:0.64074\n",
      "[88]\tvalidation_0-logloss:0.64013\n",
      "[89]\tvalidation_0-logloss:0.63966\n",
      "[90]\tvalidation_0-logloss:0.63930\n",
      "[91]\tvalidation_0-logloss:0.63894\n",
      "[92]\tvalidation_0-logloss:0.63851\n",
      "[93]\tvalidation_0-logloss:0.63802\n",
      "[94]\tvalidation_0-logloss:0.63751\n",
      "[95]\tvalidation_0-logloss:0.63690\n",
      "[96]\tvalidation_0-logloss:0.63662\n",
      "[97]\tvalidation_0-logloss:0.63641\n",
      "[98]\tvalidation_0-logloss:0.63586\n",
      "[99]\tvalidation_0-logloss:0.63545\n",
      "\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost with accuracy-focused parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    early_stopping_rounds=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Hyperparameter grid (optimized for QQQ)\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 4],          # Reduced complexity\n",
    "    \"learning_rate\": [0.05, 0.1],  # Smaller steps\n",
    "    \"subsample\": [0.8, 0.9],       # Prevent overfitting\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_alpha\": [0.1, 0.5],       # L1 regularization\n",
    "    \"reg_lambda\": [0.1, 0.5]       # L2 regularization\n",
    "}\n",
    "\n",
    "# Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train, y_train, eval_set=[(X_train, y_train)])\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98a52a-431c-4d0d-a3c5-67fe496c8bb3",
   "metadata": {},
   "source": [
    "### Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a921a43b-c902-485a-a77a-965d740d5895",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m best_model.set_params(scale_pos_weight=scale_pos_weight)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Retrain with class balancing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\callback.py:267\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    265\u001b[39m     metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m ret = \u001b[38;5;28many\u001b[39m(c.after_iteration(model, epoch, \u001b[38;5;28mself\u001b[39m.history) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\callback.py:267\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    265\u001b[39m     metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m ret = \u001b[38;5;28many\u001b[39m(\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\callback.py:463\u001b[39m, in \u001b[36mEarlyStopping.after_iteration\u001b[39m\u001b[34m(self, model, epoch, evals_log)\u001b[39m\n\u001b[32m    461\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mMust have at least 1 validation dataset for early stopping.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evals_log.keys()) < \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Get data name\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data:\n",
      "\u001b[31mValueError\u001b[39m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "# Adjust for class imbalance (if needed)\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "best_model.set_params(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Retrain with class balancing\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573fe9e-52fe-4543-8724-4f54feecdf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
